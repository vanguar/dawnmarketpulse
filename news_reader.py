import os
import requests
from datetime import datetime, timedelta

# –°–ø–∏—Å–æ–∫ –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü. –û–Ω –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ main.py –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ GPT.
INFLUENCERS_TO_TRACK = [
    {"id": "elon_musk", "name": "Elon Musk"},
    {"id": "sam_altman", "name": "Sam Altman"},
    {"id": "bill_gates", "name": "Bill Gates"},
    {"id": "jeff_bezos", "name": "Jeff Bezos"},
    {"id": "warren_buffett", "name": "Warren Buffett"},
    {"id": "donald_trump", "name": "Donald Trump"},
    {"id": "a_pompliano", "name": "Anthony Pompliano"},
    {"id": "balaji_s", "name": "Balaji Srinivasan"},
    {"id": "vitalik_buterin", "name": "Vitalik Buterin"},
    {"id": "larry_fink", "name": "Larry Fink"},
    {"id": "cz_binance", "name": "Changpeng Zhao"},
    {"id": "brian_armstrong", "name": "Brian Armstrong"},
    {"id": "cathie_wood", "name": "Cathie Wood"},
    {"id": "michael_saylor", "name": "Michael Saylor"},
    {"id": "jensen_huang", "name": "Jensen Huang"},
    {"id": "jerome_powell", "name": "Jerome Powell"},
]

def get_market_news():
    """
    –ü–æ–ª—É—á–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é –ø–æ—Ä—Ü–∏—é —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–æ–ø-5).
    """
    try:
        api_key = os.getenv("MARKETAUX_KEY")
        if not api_key:
            return "MarketAux API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è get_market_news", False

        url = "https://api.marketaux.com/v1/news/all"
        params = {
            "api_token": api_key,
            "language": "ru,en",
            "countries": "us,gb,de,cn,jp,global",
            "filter_entities": "true",
            "limit": 5, 
            "sort": "published_on",
            "group_similar": "true"
        }
        response = requests.get(url, params=params, timeout=15)
        response.raise_for_status()
        data = response.json()
        articles = data.get("data", [])

        if not articles:
            return "–†–µ–∞–ª—å–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.", False

        result = []
        for article in articles[:3]: 
            title = article.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
            source = article.get("source", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")
            result.append(f"‚Ä¢ {title} ({source})")
        return "\n".join(result), True
    except requests.exceptions.HTTPError as http_err:
        return f"‚ùó HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {http_err}", False
    except Exception as e:
        return f"‚ùó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}", False

def get_news_block():
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –±–ª–æ–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è GPT.
    """
    news_content, has_actual_news = get_market_news()
    if has_actual_news:
        return f"""–ù–æ–≤–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞ üì∞
{news_content}

‚Üí –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏: –∫—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ –∏ –≤–æ–∑–º–æ–∂–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ.""", True
    else:
        return "", False


def get_news_pool_for_gpt_analysis():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –Ω–∞–±–æ—Ä —Å–≤–µ–∂–∏—Ö –æ–±—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π (–±–µ–∑ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º),
    –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è GPT –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç description, –µ—Å–ª–∏ snippet –ø—É—Å—Ç,
    –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å).
    """
    api_key = os.getenv("MARKETAUX_KEY")
    if not api_key:
        print("‚ùó [news_reader] MARKETAUX_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ø—É–ª –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ GPT.")
        return "üó£Ô∏è –ö–ª—é—á MarketAux API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π."

    print("‚ÑπÔ∏è [news_reader] –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π GPT...")
    try:
        url = "https://api.marketaux.com/v1/news/all"
        # –£–ª—É—á—à–µ–Ω–∏–µ: –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å
        published_after_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        params = {
            "api_token": api_key,
            "language": "ru,en",
            "limit": 25, 
            "sort": "published_on",
            "published_after": published_after_date, # –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
            "group_similar": "true", 
            "countries": "us,gb,de,cn,jp,global", 
        }
        response = requests.get(url, params=params, timeout=25)
        response.raise_for_status()
        data = response.json()
        articles = data.get("data", [])

        if not articles:
            print("‚ÑπÔ∏è [news_reader] –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è GPT (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å).")
            return "üó£Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—É–ª –æ–±—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å)."

        news_texts = []
        for i, article in enumerate(articles):
            title = article.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞").strip()
            snippet = article.get("snippet", "").strip()
            # –£–ª—É—á—à–µ–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É–µ–º description, –µ—Å–ª–∏ snippet –ø—É—Å—Ç
            description = article.get("description", "").strip()
            
            content_for_gpt = snippet
            if not content_for_gpt and description:
                content_for_gpt = description
            elif not content_for_gpt:
                content_for_gpt = "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç."
            
            article_text = f"–ù–æ–≤–æ—Å—Ç—å {i+1}: {title}\n–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content_for_gpt}"
            news_texts.append(article_text)
        
        print(f"‚ÑπÔ∏è [news_reader] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π –≤ –ø—É–ª –¥–ª—è GPT (–∑–∞ {published_after_date}).")
        return "\n\n---\n\n".join(news_texts)

    except requests.exceptions.HTTPError as http_err:
        error_details = ""
        if http_err.response is not None:
            error_details = f" - Status: {http_err.response.status_code}, Response: {http_err.response.text[:200]}"
        print(f"‚ùó [news_reader] HTTP –æ—à–∏–±–∫–∞ MarketAux –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {http_err}{error_details}")
        return f"üó£Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (HTTP): {http_err.response.status_code if http_err.response is not None else 'Unknown'}"
    except requests.exceptions.RequestException as req_err:
        print(f"‚ùó [news_reader] –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {req_err}")
        return f"üó£Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π."
    except Exception as e:
        print(f"‚ùó [news_reader] –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return f"üó£Ô∏è –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π."