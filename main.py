#!/usr/bin/env python3
import pytz
import nltk
# –ò—Å–ø–æ–ª—å–∑—É–µ–º quiet=True, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ª–∏—à–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ª–æ–≥–∞—Ö –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ
nltk.download('punkt', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

import os
import sys
import requests
import openai
from datetime import datetime, timezone, date, timedelta
from time import sleep
import traceback
import re

# –ú–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
from market_reader import get_market_data_text, get_crypto_data
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ —Å–ø–∏—Å–æ–∫ –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤
from news_reader import get_news_block, get_news_pool_for_gpt_analysis, INFLUENCERS_TO_TRACK
from analyzer import keyword_alert, store_and_compare
from metrics_reader import get_derivatives_block
from whale_alert_reader import get_whale_activity_summary
from fng_reader import get_fear_and_greed_index_text
from collections import Counter
from custom_logger import log


# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
openai.api_key = os.getenv("OPENAI_KEY")
TG_TOKEN = os.getenv("TG_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
MARKETAUX_KEY = os.getenv("MARKETAUX_KEY")
COINMARKETCAP_KEY = os.getenv("COINMARKETCAP_KEY")

MODEL = "gpt-4o-mini"
TIMEOUT = 120 
TG_LIMIT_BYTES = 3800
GPT_TOKENS_MAIN_ANALYSIS = 1800 
GPT_TOKENS_INFLUENCER_ANALYSIS = 800


# --- –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è GPT (–æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑ - —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏) ---
GPT_CONTINUATION_WITH_NEWS = """‚ö†Ô∏è –í–ê–ñ–ù–û: –ù–ï –ü–û–í–¢–û–†–Ø–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –±—ã–ª–∞ —É–ø–æ–º—è–Ω—É—Ç–∞ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—É–Ω–∫—Ç–∞—Ö –∏–ª–∏ –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö. –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª —Ç–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –£–ù–ò–ö–ê–õ–¨–ù–£–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –¥–∞–π –õ–ê–ö–û–ù–ò–ß–ù–£–Æ —Å–≤–æ–¥–∫—É:
–ê–∫—Ü–∏–∏-–ª–∏–¥–µ—Ä—ã üöÄ / –ê—É—Ç—Å–∞–π–¥–µ—Ä—ã üìâ
- 2‚Äì3 –±—É–º–∞–≥–∏ —Å –∫—Ä–∞—Ç–∫–æ–π –ø—Ä–∏—á–∏–Ω–æ–π.
–ö–ª—é—á–µ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –≤–ª–∏—è–Ω–∏–µ üì∞
- –°—É—Ç—å –±–µ–∑ –ø–µ—Ä–µ—Å–∫–∞–∑–æ–≤, —Ç–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ.
‚Üí –û–±—â–∏–π –≤—ã–≤–æ–¥ üåç
- –ö—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä —Ñ–æ–Ω–¥–æ–≤–æ–≥–æ –∏ –∫—Ä–∏–ø—Ç–æ—Ä—ã–Ω–∫–∞. –ë–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—É–Ω–∫—Ç–æ–≤ —Ç–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.
–¶–∏—Ç–∞—Ç—ã –¥–Ω—è üó£
- –î–æ 2 —Ü–∏—Ç–∞—Ç –∏ –∫—Ä–∞—Ç–∫–∏–π —Å–º—ã—Å–ª.
–ß–∏—Å–ª–æ-—Ñ–∞–∫—Ç ü§î
- –û–¥–∏–Ω –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç.
‚ö°Ô∏è –ò–¥–µ—è –¥–Ω—è
- –û–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π —Å–æ–≤–µ—Ç.
‚ÄºÔ∏è –ë–µ–∑ HTML, Markdown. –î–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ.
"""

GPT_CONTINUATION_NO_NEWS = """‚ö†Ô∏è –í–ê–ñ–ù–û: –ù–ï –ü–û–í–¢–û–†–Ø–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –±—ã–ª–∞ —É–ø–æ–º—è–Ω—É—Ç–∞ –≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—É–Ω–∫—Ç–∞—Ö. –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª —Ç–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –£–ù–ò–ö–ê–õ–¨–ù–£–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
–î–∞–π –õ–ê–ö–û–ù–ò–ß–ù–£–Æ —Å–≤–æ–¥–∫—É –ø–æ —Ä—ã–Ω–∫—É (–±–µ–∑ –Ω–æ–≤–æ—Å—Ç–µ–π):
–ê–∫—Ü–∏–∏-–ª–∏–¥–µ—Ä—ã üöÄ / –ê—É—Ç—Å–∞–π–¥–µ—Ä—ã üìâ
- 2‚Äì3 –±—É–º–∞–≥–∏ –∏ –∫—Ä–∞—Ç–∫–∞—è –ø—Ä–∏—á–∏–Ω–∞.
‚Üí –û–±—â–∏–π –≤—ã–≤–æ–¥ üåç
- –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —Ä—ã–Ω–∫–∞—Ö –∏ –ø–æ—á–µ–º—É. –ë–µ–∑ –≤–æ–¥—ã –∏ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—É–Ω–∫—Ç–æ–≤ —Ç–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.
–¶–∏—Ç–∞—Ç—ã –¥–Ω—è üó£
- –î–æ 2 —Ü–∏—Ç–∞—Ç –∏ –∫—Ä–∞—Ç–∫–∏–π —Å–º—ã—Å–ª.
–ß–∏—Å–ª–æ-—Ñ–∞–∫—Ç ü§î
- –û–¥–∏–Ω –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç.
‚ö°Ô∏è –ò–¥–µ—è –¥–Ω—è
- –û–¥–∏–Ω –∫—Ä–∞—Ç–∫–∏–π actionable —Å–æ–≤–µ—Ç.
‚ÄºÔ∏è –ë–µ–∑ HTML, Markdown. –î–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ.
"""

# --- –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü (—Å —É—Å–∏–ª–µ–Ω–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π) ---
GPT_INFLUENCER_ANALYSIS_PROMPT = """‚ö†Ô∏è –í–ê–ñ–ù–û: –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª —Ç–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã" –∏ "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥") –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –£–ù–ò–ö–ê–õ–¨–ù–£–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –¥–æ—Å–ª–æ–≤–Ω–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ –¥—Ä—É–≥–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ —Ç–≤–æ–µ–≥–æ –∂–µ –æ—Ç–≤–µ—Ç–∞. –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–º–µ–Ω–Ω–æ –≤—ã–≤–æ–¥–æ–º, –∞ –Ω–µ –ø–µ—Ä–µ—Å–∫–∞–∑–æ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π.

–¢–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω —Å–ø–∏—Å–æ–∫ –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü –∏ –±–ª–æ–∫ –æ–±—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –û–ë–©–ò–ô –ë–õ–û–ö –ù–û–í–û–°–¢–ï–ô.
2. –ù–∞–π–¥–∏ –≤ —ç—Ç–∏—Ö –Ω–æ–≤–æ—Å—Ç—è—Ö –ª—é–±—ã–µ –ü–†–Ø–ú–´–ï –∏–ª–∏ –Ø–í–ù–´–ï –ö–û–°–í–ï–ù–ù–´–ï –£–ü–û–ú–ò–ù–ê–ù–ò–Ø (–≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è, –¥–µ–π—Å—Ç–≤–∏—è, –∑–Ω–∞—á–∏–º—ã–µ –Ω–æ–≤–æ—Å—Ç–∏), –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –∫–æ–º—É-–ª–∏–±–æ –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞ –ª–∏—Ü: {influencer_names_list}.
3. –ï—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–∞–π–¥–µ–Ω—ã:
    –∞. –ò–∑ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤—ã–±–µ—Ä–∏ 1-2 –ù–ê–ò–ë–û–õ–ï–ï –í–ê–ñ–ù–´–• –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä—ã–Ω–∫–æ–≤ (—Ñ–æ–Ω–¥–æ–≤—ã–π, –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã–π) –∏–ª–∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤. –û—Ç–¥–∞–≤–∞–π –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è–º –∏–ª–∏ –∞–Ω–æ–Ω—Å–∞–º, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ñ–∞–∫—Ç—É —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏–º–µ–Ω–∏.
    –±. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∞–∂–Ω–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫—Ä–∞—Ç–∫–æ –∏–∑–ª–æ–∂–∏ –µ–≥–æ —Å—É—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ò–ª–æ–Ω –ú–∞—Å–∫ –∑–∞—è–≤–∏–ª –æ..." –∏–ª–∏ "–ù–æ–≤–æ—Å—Ç—å –æ –°—ç–º–µ –ê–ª—å—Ç–º–∞–Ω–µ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞...").
    –≤. –î–∞–π –û–ë–©–ò–ô –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –í–´–í–û–î (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ —ç—Ç–∏–º –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–º –º–æ–º–µ–Ω—Ç–∞–º: —á—Ç–æ –æ–Ω–∏ –º–æ–≥—É—Ç –æ–∑–Ω–∞—á–∞—Ç—å –¥–ª—è –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, –∫–∞–∫–æ–≤—ã –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è, –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ. –≠—Ç–æ—Ç –≤—ã–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–≤–æ–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º, –∞ –Ω–µ –ø—Ä–æ—Å—Ç—ã–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º —Å—É—Ç–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π.
4. –ï—Å–ª–∏ —Å—Ä–µ–¥–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ–±—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ó–ù–ê–ß–ò–ú–´–• —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ª–∏—Ü (–∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ä—ã–Ω–∫–∏) –ù–ï –ù–ê–ô–î–ï–ù–û, –∏–ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–µ –Ω–µ—Å—É—Ç —Ä—ã–Ω–æ—á–Ω–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏, –Ω–∞–ø–∏—à–∏: "–í —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –ø–æ–¥–±–æ—Ä–∫–µ –æ–±—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–Ω–∞—á–∏–º—ã—Ö –ø—É–±–ª–∏—á–Ω—ã—Ö –∑–∞—è–≤–ª–µ–Ω–∏–π –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–µ–π, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–º–∏ –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏ –∏ —Å–ø–æ—Å–æ–±–Ω—ã—Ö –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ä—ã–Ω–∫–∏, –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ."

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∑–Ω–∞—á–∏–º—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è):
–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –æ—Ç –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü (–∏–∑ –æ–±—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π):
- –ü—Ä–æ [–ò–º—è –§–∞–º–∏–ª–∏—è]: [–°—É—Ç—å –≤–∞–∂–Ω–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è 1]
- –ü—Ä–æ [–ò–º—è –§–∞–º–∏–ª–∏—è]: [–°—É—Ç—å –≤–∞–∂–Ω–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è 2 (–µ—Å–ª–∏ –µ—Å—Ç—å)]
–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥: [–¢–≤–æ–π –≤—ã–≤–æ–¥, —Å–∏–Ω—Ç–µ–∑–∏—Ä—É—é—â–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∞ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–π –µ—ë]

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–Ω–∞—á–∏–º—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π):
[–°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∑–Ω–∞—á–∏–º—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π, –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ –ø—É–Ω–∫—Ç–µ 4]

‚ÄºÔ∏è –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç. –ë–µ–∑ Markdown. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–æ–∫ –∏ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º –≤–ª–∏—è–Ω–∏–∏. –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑, –µ—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ø—É–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ª–∏—Ü–∞—Ö –∏–ª–∏ –∏—Ö –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∏–ª–∏ –µ—Å–ª–∏ –∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –Ω–µ –∏–º–µ–µ—Ç —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.

–°–ü–ò–°–û–ö –í–õ–ò–Ø–¢–ï–õ–¨–ù–´–• –õ–ò–¶ –î–õ–Ø –ü–û–ò–°–ö–ê:
{influencer_names_list}

–û–ë–©–ò–ô –ë–õ–û–ö –ù–û–í–û–°–¢–ï–ô –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê (–æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ, —ç—Ç–æ –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏, —Ç–µ–±–µ –Ω—É–∂–Ω–æ —Å–∞–º–æ–º—É –Ω–∞–π—Ç–∏ –≤ –Ω–∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ª–∏—Ü):
---
{general_news_text_pool}
---

–¢–≤–æ–π –∞–Ω–∞–ª–∏–∑:
"""

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (log, safe_call - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
def log(msg):
    timestamp = f"[{datetime.now(timezone.utc):%Y-%m-%d %H:%M:%S} UTC]"
    print(f"{timestamp} {msg}", flush=True)

def safe_call(func, retries=3, delay=5, label="‚ùó –û—à–∏–±–∫–∞"):
    for i in range(retries):
        try:
            return func()
        except requests.exceptions.Timeout:
            log(f"{label}: –ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries} –Ω–µ —É–¥–∞–ª–∞—Å—å - –¢–∞–π–º–∞—É—Ç ({TIMEOUT}—Å)")
        except requests.exceptions.RequestException as e:
            log(f"{label}: –ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries} –Ω–µ —É–¥–∞–ª–∞—Å—å - –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
        except openai.error.OpenAIError as e: 
            log(f"{label} OpenAI: –ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries} –Ω–µ —É–¥–∞–ª–∞—Å—å - {type(e).__name__}: {e}")
        except Exception as e:
            log(f"{label}: –ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retries} –Ω–µ —É–¥–∞–ª–∞—Å—å - –û–±—â–∞—è –æ—à–∏–±–∫–∞: {type(e).__name__} - {e}")
            # log(traceback.format_exc()) 
        if i < retries - 1:
            log(f"–ü–∞—É–∑–∞ {delay} —Å–µ–∫. –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
            sleep(delay)
    log(f"{label}: –≤—Å–µ {retries} –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–µ–Ω—ã.")
    return None

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ GPT (gpt_report - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
def gpt_report():
    today_date_str = date.today().strftime("%d.%m.%Y")
    news_text_for_gpt, has_actual_news = get_news_block() 
    header_for_gpt = f"üìÖ –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –Ω–∞ {today_date_str}"
    current_gpt_prompt_name = ""
    
    if has_actual_news:
        log("üì∞ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPT_CONTINUATION_WITH_NEWS.")
        prompt_content = GPT_CONTINUATION_WITH_NEWS
        current_gpt_prompt_name = "WITH_NEWS"
        dynamic_data_for_gpt = (
            f"{header_for_gpt}\n\n"
            f"--- –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–´–ï –ù–û–í–û–°–¢–ò –†–´–ù–ö–ê (–¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞) ---\n"
            f"{news_text_for_gpt}\n\n" 
            f"--- –ó–ê–î–ê–ù–ò–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê ---\n"
            f"{prompt_content}"
        )
    else:
        log("üì∞ –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPT_CONTINUATION_NO_NEWS.")
        prompt_content = GPT_CONTINUATION_NO_NEWS
        current_gpt_prompt_name = "NO_NEWS"
        dynamic_data_for_gpt = (
            f"{header_for_gpt}\n\n"
            f"(–û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ: –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã.)\n\n"
            f"--- –ó–ê–î–ê–ù–ò–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê ---\n"
            f"{prompt_content}"
        )
    
    log(f"‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –¥–ª—è GPT (–æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑, –¥–ª–∏–Ω–∞: {len(dynamic_data_for_gpt)}). –ü—Ä–æ–º–ø—Ç: {current_gpt_prompt_name}. –ù–∞—á–∞–ª–æ: {dynamic_data_for_gpt[:200].replace(chr(10), ' ')}...")
    response = safe_call(
        lambda: openai.ChatCompletion.create(
            model=MODEL,
            messages=[{"role": "user", "content": dynamic_data_for_gpt}],
            timeout=TIMEOUT, 
            temperature=0.4,
            max_tokens=GPT_TOKENS_MAIN_ANALYSIS,
        ),
        label="‚ùó –û—à–∏–±–∫–∞ OpenAI (–æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑)"
    )
    if not response or not response.choices:
        log("‚ùå OpenAI –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")
        return "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –æ—Ç GPT." 
    
    generated_text = response.choices[0].message.content.strip()
    log(f"üìù GPT —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç ({len(generated_text)}).")
    return generated_text

# --- –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ (—Å –ø–æ–∏—Å–∫–æ–º –≤ –æ–±—â–µ–º —Ç–µ–∫—Å—Ç–µ) ---
def analyze_influencer_mentions_with_gpt(general_news_pool_text, influencer_list):
    """
    –ò—â–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü –≤ –æ–±—â–µ–º –ø—É–ª–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Ö —Å –ø–æ–º–æ—â—å—é GPT.
    """
    if not general_news_pool_text or \
       "–Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—É–ª" in general_news_pool_text.lower() or \
       "–∫–ª—é—á marketaux api –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω" in general_news_pool_text.lower() or \
       "–æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π" in general_news_pool_text.lower(): # –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—â—É—é –æ—à–∏–±–∫—É
        log(f"‚ÑπÔ∏è –ù–µ—Ç –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ –∏–ª–∏ –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏. –¢–µ–∫—Å—Ç: {general_news_pool_text}")
        return general_news_pool_text 

    influencer_names_str = ", ".join([p['name'] for p in influencer_list])
    if not influencer_names_str:
        log("‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—É—Å—Ç.")
        return "‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω."

    prompt = GPT_INFLUENCER_ANALYSIS_PROMPT.format(
        influencer_names_list=influencer_names_str,
        general_news_text_pool=general_news_pool_text
    )
    
    log(f"‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –¥–ª—è GPT (–∞–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤, –¥–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: {len(prompt)}). –ò–º–µ–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞: {influencer_names_str}. –ù–∞—á–∞–ª–æ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {general_news_pool_text[:200].replace(chr(10), ' ')}...")
    response = safe_call(
        lambda: openai.ChatCompletion.create(
            model=MODEL, 
            messages=[{"role": "user", "content": prompt}],
            timeout=TIMEOUT + 30, 
            temperature=0.5, 
            max_tokens=GPT_TOKENS_INFLUENCER_ANALYSIS 
        ),
        label="‚ùó –û—à–∏–±–∫–∞ OpenAI (–∞–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤)"
    )

    if not response or not response.choices:
        log("‚ùå OpenAI –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –∑–∞–ø—Ä–æ—Å –∞–Ω–∞–ª–∏–∑–∞ –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ –∏–ª–∏ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")
        return "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü –æ—Ç GPT (OpenAI –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª)."
    
    analysis_text = response.choices[0].message.content.strip()
    log(f"üìù GPT —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∞–Ω–∞–ª–∏–∑ –ø–æ –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–∞–º ({len(analysis_text)}).")
    return analysis_text


# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ Telegram (prepare_text, force_split_long_string, smart_chunk, send - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ---
def prepare_text(text_to_prepare):
    if not isinstance(text_to_prepare, str):
        log(f"‚ö†Ô∏è prepare_text –ø–æ–ª—É—á–∏–ª –Ω–µ —Å—Ç—Ä–æ–∫—É: {type(text_to_prepare)}. –í–æ–∑–≤—Ä–∞—â–∞—é –∫–∞–∫ –µ—Å—Ç—å.")
        return str(text_to_prepare) 
    text_to_prepare = re.sub(r'\n{3,}', '\n\n', text_to_prepare.strip())
    section_markers_regex = r"^([üìäüöÄüìâ‚Çøüì∞üó£ü§î‚ö°Ô∏èüîçüìàüß†‚öñÔ∏èüêãü§ñüåçüí°‚è±üìÖüí¨].*)"
    lines = text_to_prepare.split('\n')
    processed_lines = []
    for i, line in enumerate(lines):
        stripped_line = line.strip()
        if not stripped_line: 
            if not processed_lines or processed_lines[-1].strip(): 
                processed_lines.append("")
            continue
        processed_lines.append(line)
        if re.match(section_markers_regex, stripped_line):
            if i + 1 < len(lines) and lines[i+1].strip(): 
                processed_lines.append("") 
    final_text = "\n".join(processed_lines)
    return re.sub(r'\n{3,}', '\n\n', final_text).strip()


def force_split_long_string(long_str, limit_b):
    sub_chunks = []
    if not long_str: return sub_chunks
    encoded_str = long_str.encode('utf-8')
    current_byte_pos = 0
    while current_byte_pos < len(encoded_str):
        end_byte_pos = min(current_byte_pos + limit_b, len(encoded_str))
        byte_slice_candidate = encoded_str[current_byte_pos:end_byte_pos]
        while True:
            try:
                decoded_chunk = byte_slice_candidate.decode('utf-8')
                sub_chunks.append(decoded_chunk)
                current_byte_pos += len(byte_slice_candidate) 
                break 
            except UnicodeDecodeError:
                if len(byte_slice_candidate) > 1:
                    byte_slice_candidate = byte_slice_candidate[:-1] 
                else:
                    log(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –Ω–µ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º—ã–π –±–∞–π—Ç –ø—Ä–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Ä–µ–∑–∫–µ: {encoded_str[current_byte_pos:current_byte_pos+1]!r}")
                    current_byte_pos += 1 
                    break 
    return sub_chunks

def smart_chunk(text_to_chunk, outer_limit_bytes):
    paragraphs = text_to_chunk.split("\n\n") 
    final_result_chunks = []
    current_accumulated_parts = [] 
    current_accumulated_bytes = 0  
    for para_idx, paragraph_str in enumerate(paragraphs):
        if not paragraph_str.strip(): continue
        paragraph_bytes = paragraph_str.encode('utf-8')
        separator_bytes_len = 2 if current_accumulated_parts else 0 
        if current_accumulated_bytes + separator_bytes_len + len(paragraph_bytes) <= outer_limit_bytes:
            if current_accumulated_parts: 
                current_accumulated_parts.append("\n\n")
            current_accumulated_parts.append(paragraph_str)
            current_accumulated_bytes += separator_bytes_len + len(paragraph_bytes)
        else:
            if current_accumulated_parts:
                final_result_chunks.append("".join(current_accumulated_parts))
            current_accumulated_parts = [] 
            current_accumulated_bytes = 0
            if len(paragraph_bytes) > outer_limit_bytes:
                log(f"‚ÑπÔ∏è –ê–±–∑–∞—Ü #{para_idx} '{paragraph_str[:30].replace(chr(10),' ')}...' ({len(paragraph_bytes)}–ë > {outer_limit_bytes}–ë) –±—É–¥–µ—Ç —Ä–∞–∑—Ä–µ–∑–∞–Ω.")
                split_long_paragraph_sub_chunks = force_split_long_string(paragraph_str, outer_limit_bytes)
                if split_long_paragraph_sub_chunks:
                    final_result_chunks.extend(split_long_paragraph_sub_chunks[:-1])
                    current_accumulated_parts.append(split_long_paragraph_sub_chunks[-1])
                    current_accumulated_bytes = len(split_long_paragraph_sub_chunks[-1].encode('utf-8'))
            else: 
                current_accumulated_parts.append(paragraph_str)
                current_accumulated_bytes = len(paragraph_bytes)
    if current_accumulated_parts: 
        final_result_chunks.append("".join(current_accumulated_parts))
    return [chunk_item for chunk_item in final_result_chunks if chunk_item.strip()] 

def send(text_content, add_numeration_if_multiple_parts=False):
    prepared_text_content = prepare_text(str(text_content)) 
    prefix_max_allowance_bytes = 40 
    text_chunk_limit_for_smart_chunk = TG_LIMIT_BYTES 
    if add_numeration_if_multiple_parts:
        text_chunk_limit_for_smart_chunk = TG_LIMIT_BYTES - prefix_max_allowance_bytes
    parts_list = smart_chunk(prepared_text_content, text_chunk_limit_for_smart_chunk)
    total_parts_count = len(parts_list)
    if add_numeration_if_multiple_parts and total_parts_count == 1:
        parts_list = smart_chunk(prepared_text_content, TG_LIMIT_BYTES) 
        total_parts_count = len(parts_list)
    if not parts_list:
        log("‚ÑπÔ∏è –ù–µ—Ç —á–∞—Å—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏.")
        return
    for idx, single_part_content in enumerate(parts_list, 1):
        final_text_for_telegram = single_part_content
        log_part_prefix_display = "" 
        if add_numeration_if_multiple_parts and total_parts_count > 1:
            numeration_prefix_str = f"–ß–∞—Å—Ç—å {idx}/{total_parts_count}:\n\n"
            final_text_for_telegram = numeration_prefix_str + single_part_content
            log_part_prefix_display = f"–ß–∞—Å—Ç—å {idx}/{total_parts_count} " 
            final_text_bytes_with_prefix = len(final_text_for_telegram.encode('utf-8'))
            if final_text_bytes_with_prefix > 4096: 
                log(f"üìõ –í–ù–ò–ú–ê–ù–ò–ï! {log_part_prefix_display}–° –ü–†–ï–§–ò–ö–°–û–ú –°–õ–ò–®–ö–û–ú –î–õ–ò–ù–ù–ê–Ø ({final_text_bytes_with_prefix}–ë > 4096–ë). Telegram –û–ë–†–ï–ñ–ï–¢ –≠–¢–£ –ß–ê–°–¢–¨!")
        def make_telegram_api_call():
            return requests.post(
                f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage",
                json={"chat_id": CHANNEL_ID, "text": final_text_for_telegram, "disable_web_page_preview": True, "parse_mode": "HTML"},
                timeout=20 
            )
        response_from_tg = safe_call(make_telegram_api_call, label=f"‚ùó –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ {log_part_prefix_display}–≤ TG")
        current_part_final_bytes = len(final_text_for_telegram.encode('utf-8'))
        current_part_final_chars = len(final_text_for_telegram)
        if response_from_tg and response_from_tg.status_code == 200:
            log(f"‚úÖ {log_part_prefix_display}—É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ ({current_part_final_bytes}–ë, {current_part_final_chars} —Å–∏–º–≤.)")
        elif response_from_tg:
            error_text_preview = final_text_for_telegram[:150].replace('\n', ' ') 
            log(f"‚ùó –û—à–∏–±–∫–∞ –æ—Ç Telegram –¥–ª—è {log_part_prefix_display.strip()}: {response_from_tg.status_code} - {response_from_tg.text}")
            log(f"   –¢–µ–∫—Å—Ç –ø—Ä–æ–±–ª–µ–º–Ω–æ–π —á–∞—Å—Ç–∏ (–±–∞–π—Ç—ã: {current_part_final_bytes}, —Å–∏–º–≤: {current_part_final_chars}, –Ω–∞—á–∞–ª–æ): '{error_text_preview}...'")
        else: 
            error_text_preview = final_text_for_telegram[:150].replace('\n', ' ')
            log(f"‚ùó –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å {log_part_prefix_display.strip()} (–Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ Telegram).")
            log(f"   –¢–µ–∫—Å—Ç –ø—Ä–æ–±–ª–µ–º–Ω–æ–π —á–∞—Å—Ç–∏ (–±–∞–π—Ç—ã: {current_part_final_bytes}, —Å–∏–º–≤: {current_part_final_chars}, –Ω–∞—á–∞–ª–æ): '{error_text_preview}...'")
        if total_parts_count > 1 and idx < total_parts_count: 
            sleep_duration = 1.5 
            log(f"‚ÑπÔ∏è –ü–∞—É–∑–∞ {sleep_duration} —Å–µ–∫. –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π —á–∞—Å—Ç—å—é...")
            sleep(sleep_duration)

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ ---
def main():
    log("üöÄ –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω.")
    required_keys = ["OPENAI_KEY", "TG_TOKEN", "CHANNEL_ID", "MARKETAUX_KEY", "COINMARKETCAP_KEY"]
    keys_ok = True
    for key_name in required_keys:
        if not os.getenv(key_name):
            log(f"üìõ –ö–ª—é—á API {key_name} –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù! –°–∫—Ä–∏–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É.")
            keys_ok = False
        else:
            log(f"üîë –ö–ª—é—á API {key_name}: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    if not keys_ok:
        sys.exit("–û—à–∏–±–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª—é—á–∏ API.")

    try:
        tz_name_env = os.getenv("TZ", "Europe/Kiev") 
        try:
            user_timezone = pytz.timezone(tz_name_env)
            now_in_zone = datetime.now(user_timezone)
        except pytz.exceptions.UnknownTimeZoneError:
            log(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å –≤ TZ='{tz_name_env}'. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UTC.")
            user_timezone = timezone.utc
            now_in_zone = datetime.now(user_timezone)
            
        current_run_time_str = now_in_zone.strftime("%H:%M")
        current_date_str = now_in_zone.strftime('%d.%m.%Y')
        update_time_str = now_in_zone.strftime("%H:%M (%Z)")

        run_log_msg = f"‚è± –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω ({current_run_time_str} {now_in_zone.strftime('%Z')})"
        report_title_msg = "‚ö°Ô∏è Momentum Pulse:"
        
        # 1. –°–±–æ—Ä –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        log("üîÑ –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞–º...")
        crypto_price_block = get_crypto_data(extended=True) 
        fear_and_greed_block = get_fear_and_greed_index_text()
        derivatives_block = get_derivatives_block() 
        
        log("üîÑ –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∏—Ç–æ–≤—ã–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º...")
        whale_activity_block = get_whale_activity_summary()
        log("üêã –î–∞–Ω–Ω—ã–µ –ø–æ –∫–∏—Ç–∞–º: " + ("–ü–æ–ª—É—á–µ–Ω—ã." if whale_activity_block and "–û—à–∏–±–∫–∞" not in whale_activity_block else "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–ª–∏ –æ—à–∏–±–∫–∞."))

        log("üîÑ –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ñ–æ–Ω–¥–æ–≤–æ–º—É —Ä—ã–Ω–∫—É...")
        market_data_block = get_market_data_text()

        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∞–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü
        log("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü...")
        general_news_pool = get_news_pool_for_gpt_analysis() # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É–ª –Ω–æ–≤–æ—Å—Ç–µ–π –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        
        influencer_final_analysis_block = "" 
        # –í—ã–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ GPT, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ general_news_pool –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
        if general_news_pool and \
           "–Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—É–ª" not in general_news_pool.lower() and \
           "–∫–ª—é—á marketaux api –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω" not in general_news_pool.lower() and \
           "–æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π" not in general_news_pool.lower():
            log("üîÑ –ê–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é GPT...")
            gpt_analysis_of_mentions = analyze_influencer_mentions_with_gpt(general_news_pool, INFLUENCERS_TO_TRACK) # INFLUENCERS_TO_TRACK –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –∏–∑ news_reader
            
            if gpt_analysis_of_mentions:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—Å—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ –æ—Ç GPT –∏–ª–∏ "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
                if "–Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑" in gpt_analysis_of_mentions.lower() or \
                   "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ" in gpt_analysis_of_mentions.lower() or \
                   "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ" in gpt_analysis_of_mentions.lower(): # –î–æ–±–∞–≤–ª–µ–Ω–æ "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
                    influencer_final_analysis_block = f"üó£Ô∏è {gpt_analysis_of_mentions}" 
                else:
                    influencer_final_analysis_block = f"üí¨ –ú–Ω–µ–Ω–∏—è –ª–∏–¥–µ—Ä–æ–≤ –∏ –∏—Ö –∞–Ω–∞–ª–∏–∑ –æ—Ç GPT:\n{gpt_analysis_of_mentions}"
        else: # –ï—Å–ª–∏ –±—ã–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—É–ª–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
            influencer_final_analysis_block = general_news_pool # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ—Ç get_news_pool_for_gpt_analysis

        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –û–°–ù–û–í–ù–û–ô –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–û–ô —á–∞—Å—Ç–∏ –æ—Ç GPT
        log("üîÑ –í—ã–∑–æ–≤ GPT –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
        main_analytical_text_from_gpt = gpt_report()
        main_analytical_text_from_gpt = re.sub(r"[\*_`#]", "", main_analytical_text_from_gpt) 
        log(f"üìù –ü–æ–ª—É—á–µ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å –æ—Ç GPT (–¥–ª–∏–Ω–∞ {len(main_analytical_text_from_gpt)}).")

        # ---> –ù–ê–ß–ê–õ–û –ë–õ–û–ö–ê –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò (–ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –ë–õ–û–ö) <---
        if main_analytical_text_from_gpt.strip(): # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            log("‚ÑπÔ∏è –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ –≤ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–º –±–ª–æ–∫–µ GPT...")
            lines_gpt = main_analytical_text_from_gpt.splitlines()
            filtered_lines_gpt = []
            seen_gpt_lines = Counter() # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥–æ–µ –∏–º—è –¥–ª—è —Å—á–µ—Ç—á–∏–∫–∞
            for line_gpt in lines_gpt:
                stripped_line_content = line_gpt.strip()
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –ø—É—Å—Ç–∞—è –∏ –º—ã –µ–µ –µ—â–µ –Ω–µ –≤–∏–¥–µ–ª–∏
                if stripped_line_content and seen_gpt_lines[stripped_line_content] == 0:
                    filtered_lines_gpt.append(line_gpt)
                # –ò–ª–∏ –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø—É—Å—Ç–∞—è (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–±–∑–∞—Ü–µ–≤)
                elif not stripped_line_content:
                    filtered_lines_gpt.append(line_gpt)
                seen_gpt_lines[stripped_line_content] += 1
            
            original_len = len(main_analytical_text_from_gpt)
            main_analytical_text_from_gpt = "\n".join(filtered_lines_gpt)
            new_len = len(main_analytical_text_from_gpt)
            if original_len != new_len:
                log(f"‚ÑπÔ∏è –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ GPT –∏–∑–º–µ–Ω–µ–Ω–∞ —Å {original_len} –Ω–∞ {new_len} —Å–∏–º–≤–æ–ª–æ–≤.")
            else:
                log(f"‚ÑπÔ∏è –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ü–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ GPT –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        else:
            log("‚ÑπÔ∏è –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –±–ª–æ–∫ GPT –ø—É—Å—Ç, –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        # ---> –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò <---

        # 4. –°–±–æ—Ä–∫–∞ –í–°–ï–• –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –æ—Ç—á–µ—Ç–∞
        list_of_report_components = [
            run_log_msg,
            report_title_msg,
            crypto_price_block,
            fear_and_greed_block,
            derivatives_block, 
            whale_activity_block,
            "______________________________", 
            influencer_final_analysis_block if influencer_final_analysis_block else None, # –î–æ–±–∞–≤–ª—è–µ–º –µ—Å–ª–∏ –Ω–µ –ø—É—Å—Ç–æ–π
            "______________________________", 
            market_data_block, 
            f"ü§ñ –ê–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥—ã –æ—Ç —ç–∫—Å–ø–µ—Ä—Ç–∞ GPT –Ω–∞ {current_date_str}:",
            main_analytical_text_from_gpt, # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —É–∂–µ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            keyword_alert(main_analytical_text_from_gpt), 
            #store_and_compare(main_analytical_text_from_gpt), 
        ]
        
        # 5. –ß–∏—Å—Ç–∫–∞ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞
        valid_components = []
        for component in list_of_report_components:
            if isinstance(component, str) and component.strip():
                valid_components.append(component.strip())
            elif component is not None:
                log(f"‚ö†Ô∏è –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –æ—Ç—á–µ—Ç–∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞: {type(component)}. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω.")
                str_component = str(component).strip()
                if str_component:
                    valid_components.append(str_component)

        full_report_body_string = "\n\n".join(valid_components)
        data_update_signature = f"---\nüìÖ –î–∞–Ω–Ω—ã–µ –Ω–∞ ~ {current_date_str}, –æ–±–Ω–æ–≤–ª–µ–Ω—ã –æ–∫–æ–ª–æ {update_time_str}."
        final_telegram_message = f"{full_report_body_string}\n\n{data_update_signature}"
        
        log(f"üìÑ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å–æ–±—Ä–∞–Ω (–¥–ª–∏–Ω–∞ {len(final_telegram_message)}). –ù–∞—á–∞–ª–æ: {final_telegram_message[:250].replace(chr(10), ' ')}...")

        # 6. –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
        if final_telegram_message.strip() and final_telegram_message.strip() != report_title_msg : 
            log(f"üì® –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –≤ Telegram (TG_LIMIT_BYTES={TG_LIMIT_BYTES})...")
            send(final_telegram_message, add_numeration_if_multiple_parts=True)
            log("‚úÖ –í–µ—Å—å –æ—Ç—á—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")
        else:
            log("‚ÑπÔ∏è –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –ø—É—Å—Ç –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")

        sleep(3) 
        log("üèÅ –°–∫—Ä–∏–ø—Ç –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É.")

    except Exception as e: 
        log(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í MAIN: {type(e).__name__} - {e}")
        log(traceback.format_exc())
        try:
            if TG_TOKEN and CHANNEL_ID:
                error_message_for_tg = f"üìõ –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –°–ö–†–ò–ü–¢–ê MomentumPulse:\n{type(e).__name__}: {e}\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π."
                requests.post(
                    f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage",
                    json={"chat_id": CHANNEL_ID, "text": error_message_for_tg[:4090]}, 
                    timeout=10
                )
                log("‚ÑπÔ∏è –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram.")
            else:
                log("‚ö†Ô∏è TG_TOKEN –∏–ª–∏ CHANNEL_ID –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã, –Ω–µ –º–æ–≥—É –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –≤ Telegram.")
        except Exception as tg_err:
            log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ –≤ Telegram: {tg_err}")
        sys.exit(1)

if __name__ == "__main__":
    main()