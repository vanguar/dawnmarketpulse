#!/usr/bin/env python3
"""
Daily market report â†’ Telegram-ĞºĞ°Ğ½Ğ°Ğ».
Cron: 07:05 UTC â‰ˆ 09:05 Europe/Kyiv.
"""

import os, sys, html, requests, openai
from datetime import datetime, timezone, date
from time import sleep

# â”€â”€â”€â”€â”€â”€ ENV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai.api_key = os.getenv("OPENAI_KEY")
TG_TOKEN       = os.getenv("TG_TOKEN")
CHANNEL_ID     = os.getenv("CHANNEL_ID")

MODEL   = "gpt-4o-mini"
RETRIES = 3
TIMEOUT = 60
MAX_TG_LEN = 4096

# â”€â”€â”€â”€â”€â”€ PROMPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USER_PROMPT = """
<b>ğŸ“ˆ Ğ£Ñ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ¾Ğ±Ğ·Ğ¾Ñ€ â€¢ {date}</b>

<b>Ğ˜Ğ½Ğ´ĞµĞºÑÑ‹ ğŸ“Š</b>
â€¢ S&P 500, DAX, Nikkei, Nasdaq fut  
<i>Ğ§Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ğ´Ğ»Ñ Ğ¸Ğ½Ğ²ĞµÑÑ‚Ğ¾Ñ€Ğ°?</i>

<b>ĞĞºÑ†Ğ¸Ğ¸-Ğ»Ğ¸Ğ´ĞµÑ€Ñ‹ ğŸš€</b> Ğ¸ <b>ĞÑƒÑ‚ÑĞ°Ğ¹Ğ´ĞµÑ€Ñ‹ ğŸ“‰</b>
â€¢ Ğ¿Ğ¾ 2-3 Ğ±ÑƒĞ¼Ğ°Ğ³Ğ¸ + Ğ²Ñ‹Ğ²Ğ¾Ğ´

<b>ĞšÑ€Ğ¸Ğ¿Ñ‚Ğ° â‚¿</b>
â€¢ BTC, ETH + 3 Ğ°Ğ»ÑŒÑ‚ĞºĞ¾Ğ¸Ğ½Ğ° + Ğ²Ñ‹Ğ²Ğ¾Ğ´

<b>ĞœĞ°ĞºÑ€Ğ¾-Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ ğŸ“°</b>
â€¢ Ñ‚Ñ€Ğ¸ Ğ¿ÑƒĞ½ĞºÑ‚Ğ° + Ğ²Ğ»Ğ¸ÑĞ½Ğ¸Ğµ

<b>Ğ¦Ğ¸Ñ‚Ğ°Ñ‚Ñ‹ Ğ´Ğ½Ñ ğŸ—£</b>
â€¢ Ğ´Ğ¾ 3 Ñ†Ğ¸Ñ‚Ğ°Ñ‚ + ÑĞ¼Ñ‹ÑĞ»

<b>Ğ§Ğ¸ÑĞ»Ğ¾-Ñ„Ğ°ĞºÑ‚ ğŸ¤”</b>

<b>âš¡ï¸ Ğ˜Ğ´ĞµÑ Ğ´Ğ½Ñ</b> â€” 2-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ actionable-ÑĞ¾Ğ²ĞµÑ‚Ğ°

Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ HTML-Ñ‚ĞµĞ³Ğ¸ <b>,<i>,<u>,<s>,<code>,<a>; Ğ¼Ğ°Ñ€ĞºĞµÑ€ ÑĞ¿Ğ¸ÑĞºĞ¾Ğ² Â«â€¢ Â»; â‰¤ 450 ÑĞ»Ğ¾Ğ².
"""

# â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log(msg: str):
    ts = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')
    print(f"[{ts}] {msg}", flush=True)

def get_report() -> str:
    prompt = USER_PROMPT.format(date=date.today().isoformat())
    for n in range(1, RETRIES + 1):
        try:
            log(f"OpenAI try {n}")
            r = openai.ChatCompletion.create(
                model=MODEL,
                timeout=TIMEOUT,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                max_tokens=700,
            )
            return r.choices[0].message.content.strip()
        except Exception as e:
            log(f"OpenAI error: {e}")
            if n == RETRIES:
                raise
            sleep(2 ** n)

def safe_html(text: str) -> str:
    """Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ &, <, > â€” Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ñ‹ ÑÑ‚Ñ€Ğ¾Ğº Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ."""
    return html.escape(text, quote=False)

def split_long(text: str):
    if len(text) <= MAX_TG_LEN:
        return [text]
    parts, chunk, length = [], [], 0
    for para in text.split("\n\n"):
        para += "\n\n"
        if length + len(para) > MAX_TG_LEN:
            parts.append(''.join(chunk))
            chunk, length = [], 0
        chunk.append(para)
        length += len(para)
    if chunk:
        parts.append(''.join(chunk))
    return parts

def post_to_tg(text: str):
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    for part in split_long(text):
        r = requests.post(url, json={
            "chat_id": CHANNEL_ID,
            "text": safe_html(part),
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        }, timeout=10)
        if r.status_code != 200:
            log(f"Telegram error {r.status_code}: {r.text}")
        sleep(1)

# â”€â”€â”€â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    try:
        post_to_tg(get_report())
        log("Posted OK.")
    except Exception as err:
        log(f"Fatal: {err}")
        sys.exit(1)

if __name__ == "__main__":
    main()


